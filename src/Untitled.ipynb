{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20e939a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1dc9beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 32\n",
    "lr = 1e-3\n",
    "num_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a48bc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../nesg/nesg.csv\")\n",
    "\n",
    "fl = open(\"../nesg/nesg.fasta\")\n",
    "dic1 = {}\n",
    "chro = fl.readline().strip().split('>')[1]\n",
    "seq1 = ''\n",
    "for i in fl:\n",
    "    if '>' in i:\n",
    "        dic1[chro] = seq1\n",
    "        chro = i.strip().split('>')[1]\n",
    "        seq1 = ''\n",
    "    else:\n",
    "        seq1 += i.strip()\n",
    "dic1[chro] = seq1\n",
    "fl.close()\n",
    "\n",
    "for j in range(len(df)):\n",
    "    if df.iloc[j, 2] > 0:\n",
    "        df.iloc[j, 2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04defc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = list(dic1.values())\n",
    "df['seq'] = seq\n",
    "data = df[['seq', 'sol']].values    # ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74a34116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set(ddata):\n",
    "    \"\"\"return three list: test_set, train_set, valid_set\"\"\"\n",
    "    f_set = []\n",
    "    test_set = []   # 测试集：1941\n",
    "    train_set = []  # 训练集：5821\n",
    "    valid_set = []  # 验证集：1941\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    for f_index, test_index in split.split(ddata[:, :-1], ddata[:, -1]):\n",
    "        f_set = ddata[f_index, :]\n",
    "        test_set = ddata[test_index, :]\n",
    "\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=42)\n",
    "    for train_index, valid_index in split.split(f_set[:, :-1], f_set[:, -1]):\n",
    "        train_set = f_set[train_index, :]\n",
    "        valid_set = f_set[valid_index, :]\n",
    "\n",
    "    return test_set, train_set, valid_set\n",
    "\n",
    "\n",
    "def get_sol(d):\n",
    "    \"\"\"sol: return a tensor variable\"\"\"\n",
    "    sol = d[:, 1]\n",
    "    sol = sol.reshape(-1, 1)\n",
    "    sol_onehotencoder = OneHotEncoder(sparse=False)\n",
    "    sol_onehotencoded = sol_onehotencoder.fit_transform(sol)\n",
    "    sol_onehotencoded = torch.from_numpy(sol_onehotencoded)\n",
    "    return (sol_onehotencoded).float()\n",
    "\n",
    "\n",
    "def get_seq(d):\n",
    "    \"\"\"given an array d, return a tensor with (d.shape[0],360,20)\"\"\"\n",
    "    dic = {'X': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'A': (1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'C': (0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'D': (0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'E': (0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'F': (0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'G': (0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'H': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'I': (0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'K': (0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'L': (0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'M': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'N': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'P': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'Q': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0),\n",
    "           'R': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0),\n",
    "           'S': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0),\n",
    "           'T': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0),\n",
    "           'V': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0),\n",
    "           'W': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0),\n",
    "           'Y': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1)}\n",
    "\n",
    "    ds = np.zeros((1, 360, 20))\n",
    "    for i in d[:, 0]:\n",
    "        dds = np.zeros((1, 20))\n",
    "        for j in i:\n",
    "            dds = np.insert(dds, len(dds), dic[j], axis=0)\n",
    "            dds = dds[1:dds.shape[0]]\n",
    "\n",
    "            if dds.shape[0] <= 360:\n",
    "                dds = np.pad(dds, ((0, 360 - dds.shape[0]), (0, 0)), 'constant', constant_values=(0, 0))\n",
    "            else:\n",
    "                dds = dds[0:360]\n",
    "\n",
    "        ds = np.insert(ds, len(ds), dds, axis=0)\n",
    "\n",
    "    ds = ds[1:ds.shape[0]]\n",
    "\n",
    "    return (torch.tensor(ds)).float()\n",
    "\n",
    "\n",
    "def get_data(d):\n",
    "    x = get_seq(d)\n",
    "    y = get_sol(d)\n",
    "    ds = TensorDataset(x, y)\n",
    "    dl = DataLoader(ds, batch_size=batch, shuffle=True)\n",
    "    return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbb7e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test, train, valid = get_set(data)\n",
    "(pd.DataFrame(test, columns=['seq', 'sol'])).to_csv(\"../data/test_set.csv\", index=0)\n",
    "(pd.DataFrame(train, columns=['seq', 'sol'])).to_csv(\"../data/train_set.csv\", index=0)\n",
    "(pd.DataFrame(valid, columns=['seq', 'sol'])).to_csv(\"../data/valid_set.csv\", index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19157f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = get_data(test)\n",
    "train_set = get_data(train)\n",
    "valid_set = get_data(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8453e882",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(YModel, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=20, hidden_size=128, num_layers=2, bidirectional=True, dropout=0.5, batch_first=True)\n",
    "        self.fc = nn.Linear(128*2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ee2c0968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    val_acc_history = []\n",
    "    train_acc_history = []\n",
    "\n",
    "    since = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        train_acc = []\n",
    "        valid_acc = []\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "        model.train()\n",
    "        for iteration, (train_x, train_y) in enumerate(train_set):\n",
    "            train_x = train_x.to(device)\n",
    "            train_y = train_y.to(device)\n",
    "            train_out = model(train_x)\n",
    "            train_loss = criterion(train_out, train_y)\n",
    "#             running_loss += train_loss.item()\n",
    "            train_losses.append(train_loss.item())\n",
    "\n",
    "            pred = train_out.argmax(dim=1)\n",
    "            correct = torch.eq(pred, train_y.argmax(dim=1)).float()\n",
    "            train_acc.append((correct.sum()/len(correct)).item())\n",
    "#             running_corrects += torch.eq(pred, train_y.argmax(dim=1)).sum().item()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(\"train loss:{}\".format(np.array(train_losses).mean()))\n",
    "        print(\"train acc:{}\".format(np.array(train_acc).mean()))\n",
    "#         print(\"train loss:{}\".format(running_loss / len(train_set)))\n",
    "#         print(\"train acc:{}\".format(running_corrects / len(train_set) / batch))\n",
    "\n",
    "        \n",
    "\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "        model.eval()\n",
    "        for iteration, (valid_x, valid_y) in enumerate(valid_set):\n",
    "            valid_x = valid_x.to(device)\n",
    "            valid_y = valid_y.to(device)\n",
    "            valid_out = model(valid_x)\n",
    "            valid_loss = criterion(valid_out, valid_y)\n",
    "#             running_loss += valid_loss.item()\n",
    "            valid_losses.append(valid_loss.item())\n",
    "            pred = valid_out.argmax(dim=1)\n",
    "            correct = torch.eq(pred, valid_y.argmax(dim=1)).float()\n",
    "            valid_acc.append((correct.sum()/len(correct)).item())\n",
    "#             running_corrects += torch.eq(pred, valid_y.argmax(dim=1)).sum().item()\n",
    "#         print(\"valid loss:{}\".format(running_loss / len(valid_set)))\n",
    "#         print(\"valid acc:{}\".format(running_corrects / len(valid_set) / batch))\n",
    "        print(\"valid loss:{}\".format(np.array(valid_losses).mean()))\n",
    "        print(\"valid acc:{}\".format(np.array(valid_acc).mean()))\n",
    "        print(\"epoch:{} {}s\\n\".format(epoch, (since-time.time()) % 60))\n",
    "        since = time.time()\n",
    "\n",
    "#     running_loss = 0.0\n",
    "#     running_corrects = 0\n",
    "    test_losses = []\n",
    "    test_acc = []\n",
    "    for iteration, (test_x, test_y) in enumerate(test_set):\n",
    "        test_x = test_x.to(device)\n",
    "        test_y = test_y.to(device)\n",
    "        test_out = model(test_x)\n",
    "        test_loss = criterion(test_out, test_y)\n",
    "#         running_loss += test_loss.item()\n",
    "        test_losses.append(test_loss.item())\n",
    "        pred = test_out.argmax(dim=1)\n",
    "        correct = torch.eq(pred, test_y.argmax(dim=1)).float()\n",
    "        test_acc.append((correct.sum()/len(correct)).item())\n",
    "    print(\"test loss:{}\".format(np.array(test_losses).mean()))\n",
    "    print(\"test acc:{}\".format(np.array(test_acc).mean()))\n",
    "#         running_corrects += torch.eq(pred, test_y.argmax(dim=1)).sum().item()\n",
    "#     print(\"test loss:{}\".format(running_loss / len(test_set)))\n",
    "#     print(\"test acc:{}\".format(running_corrects / len(test_set) / batch))\n",
    "\n",
    "    torch.save(obj=model.state_dict(), f=\"models/YModel.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d27cc3db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.6719748019189625\n",
      "train acc:0.6059541420622186\n",
      "valid loss:0.670609893368893\n",
      "valid acc:0.6078893444577201\n",
      "epoch:0 36.99095892906189s\n",
      "\n",
      "train loss:0.6704661033965729\n",
      "train acc:0.6076315512041469\n",
      "valid loss:0.6699977282617913\n",
      "valid acc:0.6045081967213115\n",
      "epoch:1 36.94128227233887s\n",
      "\n",
      "train loss:0.6684827393555379\n",
      "train acc:0.6065881235913916\n",
      "valid loss:0.6682557820296678\n",
      "valid acc:0.6067622951308235\n",
      "epoch:2 36.991349935531616s\n",
      "\n",
      "train loss:0.6677142220375302\n",
      "train acc:0.6054786559972134\n",
      "valid loss:0.6703254297131398\n",
      "valid acc:0.6056352459260674\n",
      "epoch:3 37.14221668243408s\n",
      "\n",
      "train loss:0.6660457508904594\n",
      "train acc:0.6063900043021192\n",
      "valid loss:0.6689599859909933\n",
      "valid acc:0.6067622951308235\n",
      "epoch:4 37.09675335884094s\n",
      "\n",
      "train loss:0.664578514112221\n",
      "train acc:0.6074598479074437\n",
      "valid loss:0.6692869423842821\n",
      "valid acc:0.6090163935403354\n",
      "epoch:5 36.959115982055664s\n",
      "\n",
      "train loss:0.664349899842189\n",
      "train acc:0.607420224082339\n",
      "valid loss:0.6715338010279859\n",
      "valid acc:0.605430327966565\n",
      "epoch:6 36.90464377403259s\n",
      "\n",
      "train loss:0.6634150452011234\n",
      "train acc:0.6066013314239271\n",
      "valid loss:0.6691477494161637\n",
      "valid acc:0.6063524592118185\n",
      "epoch:7 37.03946137428284s\n",
      "\n",
      "train loss:0.661922523362951\n",
      "train acc:0.6084900676876634\n",
      "valid loss:0.6749282791966298\n",
      "valid acc:0.6072745902127907\n",
      "epoch:8 36.95566415786743s\n",
      "\n",
      "train loss:0.6606824967887376\n",
      "train acc:0.6102863483049057\n",
      "valid loss:0.6708504652879277\n",
      "valid acc:0.6052254098849218\n",
      "epoch:9 36.37328505516052s\n",
      "\n",
      "train loss:0.6587586147444588\n",
      "train acc:0.6088863060205847\n",
      "valid loss:0.6713554600223166\n",
      "valid acc:0.6044057378026305\n",
      "epoch:10 37.27199840545654s\n",
      "\n",
      "train loss:0.6574815708202321\n",
      "train acc:0.6150940406125981\n",
      "valid loss:0.6760097446500278\n",
      "valid acc:0.6069672132124666\n",
      "epoch:11 37.41904973983765s\n",
      "\n",
      "train loss:0.6560359520244075\n",
      "train acc:0.6079353339724488\n",
      "valid loss:0.6742013448574504\n",
      "valid acc:0.5992827869829584\n",
      "epoch:12 37.3802216053009s\n",
      "\n",
      "train loss:0.6552707770696053\n",
      "train acc:0.6106825867197015\n",
      "valid loss:0.6774148701644335\n",
      "valid acc:0.5989754098604937\n",
      "epoch:13 37.416407346725464s\n",
      "\n",
      "train loss:0.6531081012153364\n",
      "train acc:0.6143279797755755\n",
      "valid loss:0.6704806714761452\n",
      "valid acc:0.6044057378026305\n",
      "epoch:14 37.4538254737854s\n",
      "\n",
      "train loss:0.649471544957423\n",
      "train acc:0.6145921387187727\n",
      "valid loss:0.6777045643720471\n",
      "valid acc:0.6013319673108273\n",
      "epoch:15 37.09387922286987s\n",
      "\n",
      "train loss:0.6473892447385159\n",
      "train acc:0.6208527050503008\n",
      "valid loss:0.6749862139342261\n",
      "valid acc:0.6032786887200152\n",
      "epoch:16 36.81682467460632s\n",
      "\n",
      "train loss:0.6441221519649684\n",
      "train acc:0.6146845942833922\n",
      "valid loss:0.6788194697411334\n",
      "valid acc:0.6036885246390202\n",
      "epoch:17 36.682650327682495s\n",
      "\n",
      "train loss:0.6398342074109957\n",
      "train acc:0.6196904057984823\n",
      "valid loss:0.7083229144088558\n",
      "valid acc:0.5853483608511628\n",
      "epoch:18 37.26508164405823s\n",
      "\n",
      "train loss:0.6420740731633626\n",
      "train acc:0.6143279797755755\n",
      "valid loss:0.6919254523808839\n",
      "valid acc:0.563627049204756\n",
      "epoch:19 37.03191614151001s\n",
      "\n",
      "train loss:0.6371358172906624\n",
      "train acc:0.627377430325026\n",
      "valid loss:0.6912819752927686\n",
      "valid acc:0.5883196721800038\n",
      "epoch:20 36.13584041595459s\n",
      "\n",
      "train loss:0.6342641422218018\n",
      "train acc:0.6289227599953557\n",
      "valid loss:0.6915551104017945\n",
      "valid acc:0.5878073770980365\n",
      "epoch:21 37.10192251205444s\n",
      "\n",
      "train loss:0.6297873501757999\n",
      "train acc:0.6330436391162348\n",
      "valid loss:0.6954679440279476\n",
      "valid acc:0.5693647541472169\n",
      "epoch:22 37.17596650123596s\n",
      "\n",
      "train loss:0.6189023873635701\n",
      "train acc:0.6380230347206305\n",
      "valid loss:0.7032652145526448\n",
      "valid acc:0.5735655739659169\n",
      "epoch:23 37.373425006866455s\n",
      "\n",
      "train loss:0.6240262520182264\n",
      "train acc:0.6351965343231684\n",
      "valid loss:0.7005206292769948\n",
      "valid acc:0.5832991805232939\n",
      "epoch:24 37.27881717681885s\n",
      "\n",
      "test loss:0.7264643370128069\n",
      "test acc:0.5797131149495234\n"
     ]
    }
   ],
   "source": [
    "model = YModel()\n",
    "train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ae18e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mytest0 = torch.tensor([\n",
    "              [\n",
    "                  [1., 5., 5., 2.],\n",
    "                  [9., -6., 2., 8.],\n",
    "                  [-3., 7., -9., 1.]\n",
    "              ],\n",
    " \n",
    "              [\n",
    "                  [-1., 7., -5., 2.],\n",
    "                  [9., 6., 2., 8.],\n",
    "                  [3., 7., 9., 1.]\n",
    "              ]], requires_grad=True)\n",
    "mytest1 = mytest0.argmax(dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b004c1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(mytest0.requires_grad)\n",
    "print(mytest1.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3666fd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0])\n",
      "False\n",
      "torch.float32\n",
      "1.0\n",
      "1.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000001C86AEDE128>\n",
      "122\n"
     ]
    }
   ],
   "source": [
    "my = []\n",
    "for iteration, (test_x, test_y) in enumerate(test_set):\n",
    "    t = test_y.argmax(dim=1)\n",
    "    print(t)\n",
    "    print(t.requires_grad)\n",
    "    print((torch.eq(t, t).float()).dtype)\n",
    "    x = torch.eq(t, t).float()\n",
    "    print((x.sum()/len(x)).item())\n",
    "    my.append(x.sum()/len(x))\n",
    "    break\n",
    "\n",
    "print(np.array(my).mean())    \n",
    "print(train_set)    \n",
    "print(len(test_set))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
