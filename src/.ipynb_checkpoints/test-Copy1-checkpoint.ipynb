{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20e939a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b0a1374",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 32\n",
    "lr = 1e-3\n",
    "num_epochs = 25\n",
    "b = 0.25 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a48bc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../nesg/nesg.csv\")\n",
    "\n",
    "fl = open(\"../nesg/nesg.fasta\")\n",
    "dic1 = {}\n",
    "chro = fl.readline().strip().split('>')[1]\n",
    "seq1 = ''\n",
    "for i in fl:\n",
    "    if '>' in i:\n",
    "        dic1[chro] = seq1\n",
    "        chro = i.strip().split('>')[1]\n",
    "        seq1 = ''\n",
    "    else:\n",
    "        seq1 += i.strip()\n",
    "dic1[chro] = seq1\n",
    "fl.close()\n",
    "\n",
    "for j in range(len(df)):\n",
    "    if df.iloc[j, 2] > 0:\n",
    "        df.iloc[j, 2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04defc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = list(dic1.values())\n",
    "df['seq'] = seq\n",
    "data = df[['seq', 'sol']].values    # ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74a34116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set(ddata):\n",
    "    \"\"\"return three list: test_set, train_set, valid_set\"\"\"\n",
    "    f_set = []\n",
    "    test_set = []   # 测试集：1941\n",
    "    train_set = []  # 训练集：5821\n",
    "    valid_set = []  # 验证集：1941\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    for f_index, test_index in split.split(ddata[:, :-1], ddata[:, -1]):\n",
    "        f_set = ddata[f_index, :]\n",
    "        test_set = ddata[test_index, :]\n",
    "\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=42)\n",
    "    for train_index, valid_index in split.split(f_set[:, :-1], f_set[:, -1]):\n",
    "        train_set = f_set[train_index, :]\n",
    "        valid_set = f_set[valid_index, :]\n",
    "\n",
    "    return test_set, train_set, valid_set\n",
    "\n",
    "\n",
    "def get_sol(d):\n",
    "    \"\"\"sol: return a tensor variable\"\"\"\n",
    "    sol = d[:, 1]\n",
    "    sol = sol.reshape(-1, 1)\n",
    "    sol_onehotencoder = OneHotEncoder(sparse=False)\n",
    "    sol_onehotencoded = sol_onehotencoder.fit_transform(sol)\n",
    "    sol_onehotencoded = torch.from_numpy(sol_onehotencoded)\n",
    "    return (sol_onehotencoded).float()\n",
    "\n",
    "\n",
    "def get_seq(d):\n",
    "    \"\"\"given an array d, return a tensor with (d.shape[0],360,20)\"\"\"\n",
    "    dic = {'X': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'A': (1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'C': (0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'D': (0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'E': (0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'F': (0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'G': (0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'H': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'I': (0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'K': (0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'L': (0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'M': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'N': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'P': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'Q': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0),\n",
    "           'R': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0),\n",
    "           'S': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0),\n",
    "           'T': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0),\n",
    "           'V': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0),\n",
    "           'W': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0),\n",
    "           'Y': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1)}\n",
    "\n",
    "    ds = np.zeros((1, 360, 20))\n",
    "    for i in d[:, 0]:\n",
    "        dds = np.zeros((1, 20))\n",
    "        for j in i:\n",
    "            dds = np.insert(dds, len(dds), dic[j], axis=0)\n",
    "            dds = dds[1:dds.shape[0]]\n",
    "\n",
    "            if dds.shape[0] <= 360:\n",
    "                dds = np.pad(dds, ((0, 360 - dds.shape[0]), (0, 0)), 'constant', constant_values=(0, 0))\n",
    "            else:\n",
    "                dds = dds[0:360]\n",
    "\n",
    "        ds = np.insert(ds, len(ds), dds, axis=0)\n",
    "\n",
    "    ds = ds[1:ds.shape[0]]\n",
    "\n",
    "    return (torch.tensor(ds)).float()\n",
    "\n",
    "\n",
    "def get_data(d):\n",
    "    x = get_seq(d)\n",
    "    y = get_sol(d)\n",
    "    ds = TensorDataset(x, y)\n",
    "    dl = DataLoader(ds, batch_size=batch, shuffle=True)\n",
    "    return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbb7e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test, train, valid = get_set(data)\n",
    "(pd.DataFrame(test, columns=['seq', 'sol'])).to_csv(\"../data/test_set1.csv\", index=0)\n",
    "(pd.DataFrame(train, columns=['seq', 'sol'])).to_csv(\"../data/train_set1.csv\", index=0)\n",
    "(pd.DataFrame(valid, columns=['seq', 'sol'])).to_csv(\"../data/valid_set1.csv\", index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19157f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = get_data(test)\n",
    "train_set = get_data(train)\n",
    "valid_set = get_data(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8453e882",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(YModel, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=20, hidden_size=128, num_layers=2, bidirectional=True, dropout=0.5, batch_first=True)\n",
    "        self.fc = nn.Linear(128*2, 2)\n",
    "        \n",
    "        self.w = nn.Parameter(torch.Tensor(128*2, 128*2))\n",
    "        self.u = nn.Parameter(torch.Tensor(128*2, 1))\n",
    "\n",
    "        nn.init.uniform_(self.w, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.u, -0.1, 0.1)\n",
    "\n",
    "    def attention(self, x):\n",
    "        u = torch.tanh(torch.matmul(x, self.w))\n",
    "        att = torch.matmul(u, self.u)\n",
    "        att_score = F.softmax(att, dim=1)\n",
    "\n",
    "        score_x = x * att_score\n",
    "\n",
    "        context = torch.sum(score_x, dim=1)\n",
    "        return context    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.attention(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee2c0968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    val_acc_history = []\n",
    "    train_acc_history = []\n",
    "\n",
    "    since = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        train_acc = []\n",
    "        valid_acc = []\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "        model.train()\n",
    "        for iteration, (train_x, train_y) in enumerate(train_set):\n",
    "            train_x = train_x.to(device)\n",
    "            train_y = train_y.to(device)\n",
    "            train_out = model(train_x)\n",
    "            train_loss = criterion(train_out, train_y)\n",
    "#             running_loss += train_loss.item()\n",
    "            train_losses.append(train_loss.item())\n",
    "\n",
    "            pred = train_out.argmax(dim=1)\n",
    "            correct = torch.eq(pred, train_y.argmax(dim=1)).float()\n",
    "            train_acc.append((correct.sum()/len(correct)).item())\n",
    "#             running_corrects += torch.eq(pred, train_y.argmax(dim=1)).sum().item()\n",
    "            \n",
    "            flood = (train_loss-b).abs() + b\n",
    "            optimizer.zero_grad()\n",
    "            flood.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(\"train loss:{}\".format(np.array(train_losses).mean()))\n",
    "        print(\"train acc:{}\".format(np.array(train_acc).mean()))\n",
    "#         print(\"train loss:{}\".format(running_loss / len(train_set)))\n",
    "#         print(\"train acc:{}\".format(running_corrects / len(train_set) / batch))\n",
    "\n",
    "        \n",
    "\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "        model.eval()\n",
    "        for iteration, (valid_x, valid_y) in enumerate(valid_set):\n",
    "            valid_x = valid_x.to(device)\n",
    "            valid_y = valid_y.to(device)\n",
    "            valid_out = model(valid_x)\n",
    "            valid_loss = criterion(valid_out, valid_y)\n",
    "#             running_loss += valid_loss.item()\n",
    "            valid_losses.append(valid_loss.item())\n",
    "            pred = valid_out.argmax(dim=1)\n",
    "            correct = torch.eq(pred, valid_y.argmax(dim=1)).float()\n",
    "            valid_acc.append((correct.sum()/len(correct)).item())\n",
    "#             running_corrects += torch.eq(pred, valid_y.argmax(dim=1)).sum().item()\n",
    "#         print(\"valid loss:{}\".format(running_loss / len(valid_set)))\n",
    "#         print(\"valid acc:{}\".format(running_corrects / len(valid_set) / batch))\n",
    "        print(\"valid loss:{}\".format(np.array(valid_losses).mean()))\n",
    "        print(\"valid acc:{}\".format(np.array(valid_acc).mean()))\n",
    "        print(\"epoch:{} {}s\\n\".format(epoch, (since-time.time()) % 60))\n",
    "        since = time.time()\n",
    "\n",
    "#     running_loss = 0.0\n",
    "#     running_corrects = 0\n",
    "    test_losses = []\n",
    "    test_acc = []\n",
    "    for iteration, (test_x, test_y) in enumerate(test_set):\n",
    "        test_x = test_x.to(device)\n",
    "        test_y = test_y.to(device)\n",
    "        test_out = model(test_x)\n",
    "        test_loss = criterion(test_out, test_y)\n",
    "#         running_loss += test_loss.item()\n",
    "        test_losses.append(test_loss.item())\n",
    "        pred = test_out.argmax(dim=1)\n",
    "        correct = torch.eq(pred, test_y.argmax(dim=1)).float()\n",
    "        test_acc.append((correct.sum()/len(correct)).item())\n",
    "    print(\"test loss:{}\".format(np.array(test_losses).mean()))\n",
    "    print(\"test acc:{}\".format(np.array(test_acc).mean()))\n",
    "#         running_corrects += torch.eq(pred, test_y.argmax(dim=1)).sum().item()\n",
    "#     print(\"test loss:{}\".format(running_loss / len(test_set)))\n",
    "#     print(\"test acc:{}\".format(running_corrects / len(test_set) / batch))\n",
    "\n",
    "    torch.save(obj=model.state_dict(), f=\"models/YModel1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d27cc3db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.6711405109573196\n",
      "train acc:0.6076438924768469\n",
      "valid loss:0.6695818112742516\n",
      "valid acc:0.609206989888222\n",
      "epoch:0 47.2179696559906s\n",
      "\n",
      "train loss:0.6695904646600995\n",
      "train acc:0.6075932259088034\n",
      "valid loss:0.6709617164827162\n",
      "valid acc:0.604046659123513\n",
      "epoch:1 47.31780958175659s\n",
      "\n",
      "train loss:0.6705446164686601\n",
      "train acc:0.6077902624895285\n",
      "valid loss:0.6671657004664021\n",
      "valid acc:0.6102390558488907\n",
      "epoch:2 47.3099205493927s\n",
      "\n",
      "train loss:0.6695212079928472\n",
      "train acc:0.6067515984996334\n",
      "valid loss:0.670314125476345\n",
      "valid acc:0.6112711218095594\n",
      "epoch:3 47.294206619262695s\n",
      "\n",
      "train loss:0.6702808122058491\n",
      "train acc:0.6072667083897434\n",
      "valid loss:0.6691015458876087\n",
      "valid acc:0.609206989888222\n",
      "epoch:4 47.31205105781555s\n",
      "\n",
      "train loss:0.6730019823535458\n",
      "train acc:0.60761011498315\n",
      "valid loss:0.6705949748716047\n",
      "valid acc:0.6050787250841817\n",
      "epoch:5 47.21101665496826s\n",
      "\n",
      "train loss:0.6698116705967829\n",
      "train acc:0.6075932259088034\n",
      "valid loss:0.6691750134191206\n",
      "valid acc:0.6071428579668845\n",
      "epoch:6 47.190189838409424s\n",
      "\n",
      "train loss:0.6685001509530204\n",
      "train acc:0.6076607815511934\n",
      "valid loss:0.6683746826264166\n",
      "valid acc:0.6071428579668845\n",
      "epoch:7 47.187280893325806s\n",
      "\n",
      "train loss:0.6679809958070189\n",
      "train acc:0.6076523366865221\n",
      "valid loss:0.6675449513619945\n",
      "valid acc:0.6071428579668845\n",
      "epoch:8 47.2055401802063s\n",
      "\n",
      "train loss:0.6675663145033868\n",
      "train acc:0.6077987073541997\n",
      "valid loss:0.6677717008898335\n",
      "valid acc:0.6107430881069552\n",
      "epoch:9 47.19804668426514s\n",
      "\n",
      "train loss:0.6680996804446965\n",
      "train acc:0.6081167806635847\n",
      "valid loss:0.6685933970635937\n",
      "valid acc:0.604046659123513\n",
      "epoch:10 47.20256471633911s\n",
      "\n",
      "train loss:0.6676306809697833\n",
      "train acc:0.6077480407861563\n",
      "valid loss:0.6636185319192948\n",
      "valid acc:0.6138392859889615\n",
      "epoch:11 47.171608686447144s\n",
      "\n",
      "train loss:0.6657147414081699\n",
      "train acc:0.6076354482671716\n",
      "valid loss:0.6644546351125163\n",
      "valid acc:0.6112711218095594\n",
      "epoch:12 47.16343426704407s\n",
      "\n",
      "train loss:0.6661274878533332\n",
      "train acc:0.6100055169273209\n",
      "valid loss:0.6680819546022723\n",
      "valid acc:0.6081749239275532\n",
      "epoch:13 47.17911505699158s\n",
      "\n",
      "train loss:0.6643135567287822\n",
      "train acc:0.6091723337278261\n",
      "valid loss:0.6667874186269699\n",
      "valid acc:0.6081749239275532\n",
      "epoch:14 47.181262254714966s\n",
      "\n",
      "train loss:0.663658911055261\n",
      "train acc:0.6051724913356068\n",
      "valid loss:0.66588939966694\n",
      "valid acc:0.6067588329315186\n",
      "epoch:15 47.194512367248535s\n",
      "\n",
      "train loss:0.662294328212738\n",
      "train acc:0.6120912897717822\n",
      "valid loss:0.672129056146068\n",
      "valid acc:0.6015745016836351\n",
      "epoch:16 47.18872356414795s\n",
      "\n",
      "train loss:0.6633750442620162\n",
      "train acc:0.6090006304311228\n",
      "valid loss:0.6685204140601619\n",
      "valid acc:0.6015985031281749\n",
      "epoch:17 47.210676193237305s\n",
      "\n",
      "train loss:0.6616383601020981\n",
      "train acc:0.6105121819527595\n",
      "valid loss:0.6692602519066103\n",
      "valid acc:0.6025825661997641\n",
      "epoch:18 47.151740312576294s\n",
      "\n",
      "train loss:0.6618355971116286\n",
      "train acc:0.6137661003804469\n",
      "valid loss:0.6749629301409568\n",
      "valid acc:0.585397465575126\n",
      "epoch:19 47.13987874984741s\n",
      "\n",
      "train loss:0.6632480058041248\n",
      "train acc:0.6110526251268911\n",
      "valid loss:0.6681599367049432\n",
      "valid acc:0.6092789942218412\n",
      "epoch:20 47.15042543411255s\n",
      "\n",
      "train loss:0.6598117187782958\n",
      "train acc:0.6117816606720725\n",
      "valid loss:0.668325662612915\n",
      "valid acc:0.6041426658630371\n",
      "epoch:21 47.146180391311646s\n",
      "\n",
      "train loss:0.658953886110704\n",
      "train acc:0.6160489098056332\n",
      "valid loss:0.6719506690579076\n",
      "valid acc:0.5880376350495123\n",
      "epoch:22 47.13475060462952s\n",
      "\n",
      "train loss:0.657129799926674\n",
      "train acc:0.6190269766273079\n",
      "valid loss:0.6752081763359808\n",
      "valid acc:0.6016945089063337\n",
      "epoch:23 47.15257406234741s\n",
      "\n",
      "train loss:0.6558668416935008\n",
      "train acc:0.619156457565643\n",
      "valid loss:0.6763222852060872\n",
      "valid acc:0.6010464670196656\n",
      "epoch:24 47.133569955825806s\n",
      "\n",
      "test loss:0.6801876521879627\n",
      "test acc:0.6093029956663808\n"
     ]
    }
   ],
   "source": [
    "model = YModel()\n",
    "train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ae18e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model):\n",
    "    model.load_state_dict(torch.load(\"models/YModel1.pth\"))\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    test_losses = []\n",
    "    test_acc = []\n",
    "    for iteration, (test_x, test_y) in enumerate(test_set):\n",
    "        test_x = test_x.to(device)\n",
    "        test_y = test_y.to(device)\n",
    "        test_out = model(test_x)\n",
    "        test_loss = criterion(test_out, test_y)\n",
    "#         running_loss += test_loss.item()\n",
    "        test_losses.append(test_loss.item())\n",
    "        pred = test_out.argmax(dim=1)\n",
    "        correct = torch.eq(pred, test_y.argmax(dim=1)).float()\n",
    "        test_acc.append((correct.sum()/len(correct)).item())\n",
    "    print(\"test loss:{}\".format(np.array(test_losses).mean()))\n",
    "    print(\"test acc:{}\".format(np.array(test_acc).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2baa25ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'criterion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-ae2e7907ba4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-35-e2b4f6a36abf>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mtest_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mtest_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mtest_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;31m#         running_loss += test_loss.item()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mtest_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'criterion' is not defined"
     ]
    }
   ],
   "source": [
    "predict(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
