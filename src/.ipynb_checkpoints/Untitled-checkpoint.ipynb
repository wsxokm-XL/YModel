{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20e939a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1c9700a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 16\n",
    "lr = 1e-3\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a48bc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../nesg/nesg.csv\")\n",
    "\n",
    "fl = open(\"../nesg/nesg.fasta\")\n",
    "dic1 = {}\n",
    "chro = fl.readline().strip().split('>')[1]\n",
    "seq1 = ''\n",
    "for i in fl:\n",
    "    if '>' in i:\n",
    "        dic1[chro] = seq1\n",
    "        chro = i.strip().split('>')[1]\n",
    "        seq1 = ''\n",
    "    else:\n",
    "        seq1 += i.strip()\n",
    "dic1[chro] = seq1\n",
    "fl.close()\n",
    "\n",
    "for j in range(len(df)):\n",
    "    if df.iloc[j, 2] > 0:\n",
    "        df.iloc[j, 2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04defc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = list(dic1.values())\n",
    "df['seq'] = seq\n",
    "data = df[['seq', 'sol']].values    # ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74a34116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set(ddata):\n",
    "    \"\"\"return three list: test_set, train_set, valid_set\"\"\"\n",
    "    f_set = []\n",
    "    test_set = []   # 测试集：1941\n",
    "    train_set = []  # 训练集：5821\n",
    "    valid_set = []  # 验证集：1941\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    for f_index, test_index in split.split(ddata[:, :-1], ddata[:, -1]):\n",
    "        f_set = ddata[f_index, :]\n",
    "        test_set = ddata[test_index, :]\n",
    "\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=42)\n",
    "    for train_index, valid_index in split.split(f_set[:, :-1], f_set[:, -1]):\n",
    "        train_set = f_set[train_index, :]\n",
    "        valid_set = f_set[valid_index, :]\n",
    "\n",
    "    return test_set, train_set, valid_set\n",
    "\n",
    "\n",
    "def get_sol(d):\n",
    "    \"\"\"sol: return a tensor variable\"\"\"\n",
    "    sol = d[:, 1]\n",
    "    sol = sol.reshape(-1, 1)\n",
    "    sol_onehotencoder = OneHotEncoder(sparse=False)\n",
    "    sol_onehotencoded = sol_onehotencoder.fit_transform(sol)\n",
    "    sol_onehotencoded = torch.from_numpy(sol_onehotencoded)\n",
    "    return (sol_onehotencoded).float()\n",
    "\n",
    "\n",
    "def get_seq(d):\n",
    "    \"\"\"given an array d, return a tensor with (d.shape[0],360,20)\"\"\"\n",
    "    dic = {'X': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'A': (1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'C': (0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'D': (0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'E': (0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'F': (0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'G': (0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'H': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'I': (0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'K': (0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'L': (0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'M': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'N': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'P': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'Q': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0),\n",
    "           'R': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0),\n",
    "           'S': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0),\n",
    "           'T': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0),\n",
    "           'V': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0),\n",
    "           'W': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0),\n",
    "           'Y': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1)}\n",
    "\n",
    "    ds = np.zeros((1, 360, 20))\n",
    "    for i in d[:, 0]:\n",
    "        dds = np.zeros((1, 20))\n",
    "        for j in i:\n",
    "            dds = np.insert(dds, len(dds), dic[j], axis=0)\n",
    "            dds = dds[1:dds.shape[0]]\n",
    "\n",
    "            if dds.shape[0] <= 360:\n",
    "                dds = np.pad(dds, ((0, 360 - dds.shape[0]), (0, 0)), 'constant', constant_values=(0, 0))\n",
    "            else:\n",
    "                dds = dds[0:360]\n",
    "\n",
    "        ds = np.insert(ds, len(ds), dds, axis=0)\n",
    "\n",
    "    ds = ds[1:ds.shape[0]]\n",
    "\n",
    "    return (torch.tensor(ds)).float()\n",
    "\n",
    "\n",
    "def get_data(d):\n",
    "    x = get_seq(d)\n",
    "    y = get_sol(d)\n",
    "    ds = TensorDataset(x, y)\n",
    "    dl = DataLoader(ds, batch_size=batch, shuffle=True)\n",
    "    return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbb7e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test, train, valid = get_set(data)\n",
    "(pd.DataFrame(test, columns=['seq', 'sol'])).to_csv(\"../data/test_set.csv\", index=0)\n",
    "(pd.DataFrame(train, columns=['seq', 'sol'])).to_csv(\"../data/train_set.csv\", index=0)\n",
    "(pd.DataFrame(valid, columns=['seq', 'sol'])).to_csv(\"../data/valid_set.csv\", index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19157f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = get_data(test)\n",
    "train_set = get_data(train)\n",
    "valid_set = get_data(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8453e882",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(YModel, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=20, hidden_size=128, num_layers=2, bidirectional=True, dropout=0.5, batch_first=True)\n",
    "        self.fc = nn.Linear(128*2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ee2c0968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    val_acc_history = []\n",
    "    train_acc_history = []\n",
    "\n",
    "    since = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        train_acc = []\n",
    "        valid_acc = []\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "        model.train()\n",
    "        for iteration, (train_x, train_y) in enumerate(train_set):\n",
    "            train_x = train_x.to(device)\n",
    "            train_y = train_y.to(device)\n",
    "            train_out = model(train_x)\n",
    "            train_loss = criterion(train_out, train_y)\n",
    "#             running_loss += train_loss.item()\n",
    "            train_losses.append(train_loss.item())\n",
    "\n",
    "            pred = train_out.argmax(dim=1)\n",
    "            correct = torch.eq(pred, train_y.argmax(dim=1)).float()\n",
    "            train_acc.append((correct.sum()/len(correct)).item())\n",
    "#             running_corrects += torch.eq(pred, train_y.argmax(dim=1)).sum().item()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(\"train loss:{}\".format(np.array(train_losses).mean()))\n",
    "        print(\"train acc:{}\".format(np.array(train_acc).mean()))\n",
    "#         print(\"train loss:{}\".format(running_loss / len(train_set)))\n",
    "#         print(\"train acc:{}\".format(running_corrects / len(train_set) / batch))\n",
    "\n",
    "        \n",
    "\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "        model.eval()\n",
    "        for iteration, (valid_x, valid_y) in enumerate(valid_set):\n",
    "            valid_x = valid_x.to(device)\n",
    "            valid_y = valid_y.to(device)\n",
    "            valid_out = model(valid_x)\n",
    "            valid_loss = criterion(valid_out, valid_y)\n",
    "#             running_loss += valid_loss.item()\n",
    "            valid_losses.append(valid_loss.item())\n",
    "            pred = valid_out.argmax(dim=1)\n",
    "            correct = torch.eq(pred, valid_y.argmax(dim=1)).float()\n",
    "            valid_acc.append((correct.sum()/len(correct)).item())\n",
    "#             running_corrects += torch.eq(pred, valid_y.argmax(dim=1)).sum().item()\n",
    "#         print(\"valid loss:{}\".format(running_loss / len(valid_set)))\n",
    "#         print(\"valid acc:{}\".format(running_corrects / len(valid_set) / batch))\n",
    "        print(\"valid loss:{}\".format(np.array(valid_losses).mean()))\n",
    "        print(\"valid acc:{}\".format(np.array(valid_acc).mean()))\n",
    "        print(\"epoch:{} {}s\\n\".format(epoch, (since-time.time()) % 60))\n",
    "        since = time.time()\n",
    "\n",
    "#     running_loss = 0.0\n",
    "#     running_corrects = 0\n",
    "    test_losses = []\n",
    "    test_acc = []\n",
    "    for iteration, (test_x, test_y) in enumerate(test_set):\n",
    "        test_x = test_x.to(device)\n",
    "        test_y = test_y.to(device)\n",
    "        test_out = model(test_x)\n",
    "        test_loss = criterion(test_out, test_y)\n",
    "#         running_loss += test_loss.item()\n",
    "        test_losses.append(test_loss.item())\n",
    "        pred = test_out.argmax(dim=1)\n",
    "        correct = torch.eq(pred, test_y.argmax(dim=1)).float()\n",
    "        test_acc.append((correct.sum()/len(correct)).item())\n",
    "    print(\"test loss:{}\".format(np.array(test_losses).mean()))\n",
    "    print(\"test acc:{}\".format(np.array(test_acc).mean()))\n",
    "#         running_corrects += torch.eq(pred, test_y.argmax(dim=1)).sum().item()\n",
    "#     print(\"test loss:{}\".format(running_loss / len(test_set)))\n",
    "#     print(\"test acc:{}\".format(running_corrects / len(test_set) / batch))\n",
    "\n",
    "    torch.save(obj=model.state_dict(), f=\"models/YModel.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27cc3db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.6711536783438462\n",
      "train acc:0.6077107988543563\n",
      "valid loss:0.6689866202287986\n",
      "valid acc:0.6090163935403354\n",
      "epoch:0 37.92823338508606s\n",
      "\n",
      "train loss:0.6699995685082215\n",
      "train acc:0.607750422679461\n",
      "valid loss:0.6689203655133482\n",
      "valid acc:0.6067622951308235\n",
      "epoch:1 37.98569941520691s\n",
      "\n",
      "train loss:0.6702381350345664\n",
      "train acc:0.6050956255787021\n",
      "valid loss:0.6726098612683719\n",
      "valid acc:0.6078893444577201\n",
      "epoch:2 37.91990303993225s\n",
      "\n",
      "train loss:0.6714276055713276\n",
      "train acc:0.6074730558218536\n",
      "valid loss:0.6699958946861204\n",
      "valid acc:0.6078893444577201\n",
      "epoch:3 37.885456562042236s\n",
      "\n",
      "train loss:0.6702164653893355\n",
      "train acc:0.6076711750292516\n",
      "valid loss:0.6700884523938914\n",
      "valid acc:0.6078893444577201\n",
      "epoch:4 37.89004588127136s\n",
      "\n",
      "train loss:0.6703692763061314\n",
      "train acc:0.6075919273790422\n",
      "valid loss:0.670812022002017\n",
      "valid acc:0.6056352459260674\n",
      "epoch:5 37.82050061225891s\n",
      "\n",
      "train loss:0.6702588970189566\n",
      "train acc:0.6076711750292516\n",
      "valid loss:0.6692791918262107\n",
      "valid acc:0.6090163935403354\n",
      "epoch:6 37.84321475028992s\n",
      "\n",
      "train loss:0.6698059438021629\n",
      "train acc:0.6076711750292516\n",
      "valid loss:0.668465859577304\n",
      "valid acc:0.6090163935403354\n",
      "epoch:7 37.87600612640381s\n",
      "\n",
      "train loss:0.6693967765831685\n",
      "train acc:0.6075919273790422\n",
      "valid loss:0.6690493108796292\n",
      "valid acc:0.6078893444577201\n",
      "epoch:8 37.778669118881226s\n",
      "\n",
      "train loss:0.6690459777038176\n",
      "train acc:0.6076315512041469\n",
      "valid loss:0.6691310791695704\n",
      "valid acc:0.6067622951308235\n",
      "epoch:9 37.811121702194214s\n",
      "\n",
      "train loss:0.6679493303482349\n",
      "train acc:0.6091372570493719\n",
      "valid loss:0.6688481676773946\n",
      "valid acc:0.6078893444577201\n",
      "epoch:10 37.772828340530396s\n",
      "\n",
      "train loss:0.6686465750028799\n",
      "train acc:0.6072749367782048\n",
      "valid loss:0.6688828219155796\n",
      "valid acc:0.6067622951308235\n",
      "epoch:11 37.80049014091492s\n",
      "\n",
      "train loss:0.6692233290318604\n",
      "train acc:0.6076843829436617\n",
      "valid loss:0.6688431911781186\n",
      "valid acc:0.6067622951308235\n",
      "epoch:12 37.89024329185486s\n",
      "\n",
      "train loss:0.6685556432048043\n",
      "train acc:0.6077107988543563\n",
      "valid loss:0.6679102011391373\n",
      "valid acc:0.6101434426229508\n",
      "epoch:13 37.839929819107056s\n",
      "\n",
      "train loss:0.6685622232955891\n",
      "train acc:0.6076711750292516\n",
      "valid loss:0.6678583353269295\n",
      "valid acc:0.6090163935403354\n",
      "epoch:14 37.847217321395874s\n",
      "\n",
      "train loss:0.6685850851155899\n",
      "train acc:0.6077107988543563\n",
      "valid loss:0.6676854549861345\n",
      "valid acc:0.6101434426229508\n",
      "epoch:15 37.88741970062256s\n",
      "\n",
      "train loss:0.667807861835092\n",
      "train acc:0.6075126796469583\n",
      "valid loss:0.6694874641348104\n",
      "valid acc:0.6090163935403354\n",
      "epoch:16 37.864012718200684s\n",
      "\n",
      "train loss:0.6684920103340358\n",
      "train acc:0.6076315512041469\n",
      "valid loss:0.6698311635705291\n",
      "valid acc:0.6056352459260674\n",
      "epoch:17 37.873690605163574s\n",
      "\n",
      "train loss:0.6689350454361884\n",
      "train acc:0.6076711750292516\n",
      "valid loss:0.6682202400731259\n",
      "valid acc:0.6078893444577201\n",
      "epoch:18 37.846160650253296s\n",
      "\n",
      "train loss:0.6682547894152966\n",
      "train acc:0.6076711750292516\n",
      "valid loss:0.6673185788705701\n",
      "valid acc:0.6101434426229508\n",
      "epoch:19 37.85382032394409s\n",
      "\n",
      "train loss:0.6682683028035111\n",
      "train acc:0.6075126796469583\n",
      "valid loss:0.6690635568782931\n",
      "valid acc:0.6067622951308235\n",
      "epoch:20 37.86858129501343s\n",
      "\n",
      "train loss:0.6681009126561028\n",
      "train acc:0.6076711750292516\n",
      "valid loss:0.6710813797888209\n",
      "valid acc:0.6078893444577201\n",
      "epoch:21 37.77997803688049s\n",
      "\n",
      "train loss:0.6683368784385723\n",
      "train acc:0.6075523035539375\n",
      "valid loss:0.6689277213127887\n",
      "valid acc:0.6078893444577201\n",
      "epoch:22 37.77247190475464s\n",
      "\n",
      "train loss:0.6683664393948985\n",
      "train acc:0.6075523035539375\n",
      "valid loss:0.6697907242618624\n",
      "valid acc:0.6067622951308235\n",
      "epoch:23 37.80131530761719s\n",
      "\n",
      "train loss:0.6676121236203791\n",
      "train acc:0.6075126796469583\n",
      "valid loss:0.6698260805645927\n",
      "valid acc:0.6067622951308235\n",
      "epoch:24 37.76480007171631s\n",
      "\n",
      "train loss:0.6678825464549956\n",
      "train acc:0.6076315512041469\n",
      "valid loss:0.6689568801981504\n",
      "valid acc:0.6078893444577201\n",
      "epoch:25 37.79762268066406s\n",
      "\n",
      "train loss:0.6672564636874985\n",
      "train acc:0.6077107988543563\n",
      "valid loss:0.6690986752510071\n",
      "valid acc:0.6078893444577201\n",
      "epoch:26 37.60120129585266s\n",
      "\n",
      "train loss:0.667651422894918\n",
      "train acc:0.6077107988543563\n",
      "valid loss:0.6689606523904644\n",
      "valid acc:0.6090163935403354\n",
      "epoch:27 37.52059555053711s\n",
      "\n",
      "train loss:0.6671030015408338\n",
      "train acc:0.6075919273790422\n"
     ]
    }
   ],
   "source": [
    "model = YModel()\n",
    "train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ae18e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mytest0 = torch.tensor([\n",
    "              [\n",
    "                  [1., 5., 5., 2.],\n",
    "                  [9., -6., 2., 8.],\n",
    "                  [-3., 7., -9., 1.]\n",
    "              ],\n",
    " \n",
    "              [\n",
    "                  [-1., 7., -5., 2.],\n",
    "                  [9., 6., 2., 8.],\n",
    "                  [3., 7., 9., 1.]\n",
    "              ]], requires_grad=True)\n",
    "mytest1 = mytest0.argmax(dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12c95b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(mytest0.requires_grad)\n",
    "print(mytest1.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f066364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0])\n",
      "False\n",
      "torch.float32\n",
      "1.0\n",
      "1.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000001C86AEDE128>\n",
      "122\n"
     ]
    }
   ],
   "source": [
    "my = []\n",
    "for iteration, (test_x, test_y) in enumerate(test_set):\n",
    "    t = test_y.argmax(dim=1)\n",
    "    print(t)\n",
    "    print(t.requires_grad)\n",
    "    print((torch.eq(t, t).float()).dtype)\n",
    "    x = torch.eq(t, t).float()\n",
    "    print((x.sum()/len(x)).item())\n",
    "    my.append(x.sum()/len(x))\n",
    "    break\n",
    "\n",
    "print(np.array(my).mean())    \n",
    "print(train_set)    \n",
    "print(len(test_set))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
