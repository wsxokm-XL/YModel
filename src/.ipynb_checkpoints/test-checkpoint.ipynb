{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20e939a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b0a1374",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 8\n",
    "lr = 1e-3\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a48bc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../nesg/nesg.csv\")\n",
    "\n",
    "fl = open(\"../nesg/nesg.fasta\")\n",
    "dic1 = {}\n",
    "chro = fl.readline().strip().split('>')[1]\n",
    "seq1 = ''\n",
    "for i in fl:\n",
    "    if '>' in i:\n",
    "        dic1[chro] = seq1\n",
    "        chro = i.strip().split('>')[1]\n",
    "        seq1 = ''\n",
    "    else:\n",
    "        seq1 += i.strip()\n",
    "dic1[chro] = seq1\n",
    "fl.close()\n",
    "\n",
    "for j in range(len(df)):\n",
    "    if df.iloc[j, 2] > 0:\n",
    "        df.iloc[j, 2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04defc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = list(dic1.values())\n",
    "df['seq'] = seq\n",
    "data = df[['seq', 'sol']].values    # ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74a34116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set(ddata):\n",
    "    \"\"\"return three list: test_set, train_set, valid_set\"\"\"\n",
    "    f_set = []\n",
    "    test_set = []   # 测试集：1941\n",
    "    train_set = []  # 训练集：5821\n",
    "    valid_set = []  # 验证集：1941\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    for f_index, test_index in split.split(ddata[:, :-1], ddata[:, -1]):\n",
    "        f_set = ddata[f_index, :]\n",
    "        test_set = ddata[test_index, :]\n",
    "\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=42)\n",
    "    for train_index, valid_index in split.split(f_set[:, :-1], f_set[:, -1]):\n",
    "        train_set = f_set[train_index, :]\n",
    "        valid_set = f_set[valid_index, :]\n",
    "\n",
    "    return test_set, train_set, valid_set\n",
    "\n",
    "\n",
    "def get_sol(d):\n",
    "    \"\"\"sol: return a tensor variable\"\"\"\n",
    "    sol = d[:, 1]\n",
    "    sol = sol.reshape(-1, 1)\n",
    "    sol_onehotencoder = OneHotEncoder(sparse=False)\n",
    "    sol_onehotencoded = sol_onehotencoder.fit_transform(sol)\n",
    "    sol_onehotencoded = torch.from_numpy(sol_onehotencoded)\n",
    "    return (sol_onehotencoded).float()\n",
    "\n",
    "\n",
    "def get_seq(d):\n",
    "    \"\"\"given an array d, return a tensor with (d.shape[0],360,20)\"\"\"\n",
    "    dic = {'X': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'A': (1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'C': (0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'D': (0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'E': (0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'F': (0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'G': (0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'H': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'I': (0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'K': (0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'L': (0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'M': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'N': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'P': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0),\n",
    "           'Q': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0),\n",
    "           'R': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0),\n",
    "           'S': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0),\n",
    "           'T': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0),\n",
    "           'V': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0),\n",
    "           'W': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0),\n",
    "           'Y': (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1)}\n",
    "\n",
    "    ds = np.zeros((1, 360, 20))\n",
    "    for i in d[:, 0]:\n",
    "        dds = np.zeros((1, 20))\n",
    "        for j in i:\n",
    "            dds = np.insert(dds, len(dds), dic[j], axis=0)\n",
    "            dds = dds[1:dds.shape[0]]\n",
    "\n",
    "            if dds.shape[0] <= 360:\n",
    "                dds = np.pad(dds, ((0, 360 - dds.shape[0]), (0, 0)), 'constant', constant_values=(0, 0))\n",
    "            else:\n",
    "                dds = dds[0:360]\n",
    "\n",
    "        ds = np.insert(ds, len(ds), dds, axis=0)\n",
    "\n",
    "    ds = ds[1:ds.shape[0]]\n",
    "\n",
    "    return (torch.tensor(ds)).float()\n",
    "\n",
    "\n",
    "def get_data(d):\n",
    "    x = get_seq(d)\n",
    "    y = get_sol(d)\n",
    "    ds = TensorDataset(x, y)\n",
    "    dl = DataLoader(ds, batch_size=batch, shuffle=True)\n",
    "    return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbb7e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test, train, valid = get_set(data)\n",
    "(pd.DataFrame(test, columns=['seq', 'sol'])).to_csv(\"../data/test_set.csv\", index=0)\n",
    "(pd.DataFrame(train, columns=['seq', 'sol'])).to_csv(\"../data/train_set.csv\", index=0)\n",
    "(pd.DataFrame(valid, columns=['seq', 'sol'])).to_csv(\"../data/valid_set.csv\", index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19157f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = get_data(test)\n",
    "train_set = get_data(train)\n",
    "valid_set = get_data(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8453e882",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(YModel, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=20, hidden_size=128, num_layers=2, bidirectional=True, dropout=0.5, batch_first=True)\n",
    "        self.fc = nn.Linear(128*2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee2c0968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    val_acc_history = []\n",
    "    train_acc_history = []\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    since = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        model.train()\n",
    "        for iteration, (train_x, train_y) in enumerate(train_set):\n",
    "            train_x = train_x.to(device)\n",
    "            train_y = train_y.to(device)\n",
    "            train_out = model(train_x)\n",
    "            train_loss = criterion(train_out, train_y)\n",
    "            running_loss += train_loss.item()\n",
    "            train_losses.append(train_loss)\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "#             pred = train_out.argmax(dim=1)\n",
    "#             running_corrects += torch.eq(pred, train_y.argmax(dim=1)).sum()\n",
    "            \n",
    "        print(\"train loss:{}\".format(running_loss / len(train_set)))\n",
    "#         print(\"train acc:{}\".format(running_corrects / len(train_set)))\n",
    "        \n",
    "\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "#         model.eval()\n",
    "#         for iteration, (valid_x, valid_y) in enumerate(valid_set):\n",
    "#             valid_x = valid_x.to(device)\n",
    "#             valid_y = valid_y.to(device)\n",
    "#             valid_out = model(valid_x)\n",
    "#             valid_loss = criterion(valid_out, valid_y)\n",
    "#             running_loss += valid_loss.item()\n",
    "#             valid_losses.append(valid_loss)\n",
    "#             pred = valid_out.argmax(dim=1)\n",
    "#             running_corrects += torch.eq(pred, valid_y.argmax(dim=1)).sum()\n",
    "#         print(\"valid loss:{}\".format(running_loss / len(valid_set)))\n",
    "#         print(\"valid acc:{}\".format(running_corrects / len(valid_set)))\n",
    "\n",
    "        print(\"epoch:{} {}s\\n\".format(epoch, (since-time.time()) % 60))\n",
    "        since = time.time()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    for iteration, (test_x, test_y) in enumerate(test_set):\n",
    "        test_x = test_x.to(device)\n",
    "        test_y = test_y.to(device)\n",
    "        test_out = model(test_x)\n",
    "        valid_loss = criterion(test_out, test_y)\n",
    "        running_loss += valid_loss.item()\n",
    "        valid_losses.append(valid_loss)\n",
    "        pred = test_out.argmax(dim=1)\n",
    "        running_corrects += torch.eq(pred, test_y.argmax(dim=1)).sum()\n",
    "    print(\"test loss:{}\".format(running_loss / len(test_set)))\n",
    "    print(\"test acc:{}\".format(running_corrects / len(test_set)))\n",
    "\n",
    "    torch.save(obj=model.state_dict(), f=\"models/YModel.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27cc3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.671424784911037\n",
      "train loss:0.6710403996987404\n",
      "train loss:0.6691822405280985\n",
      "train loss:0.669025858277415\n",
      "train loss:0.6714154564259902\n"
     ]
    }
   ],
   "source": [
    "model = YModel()\n",
    "train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ae18e3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-67308a3357d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'lr' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
